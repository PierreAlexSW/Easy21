{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from Environment import Easy21\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_feature(state, action):\n",
    "    \n",
    "    def turn_couple_to_index(couple):\n",
    "        [a,d,p] = couple\n",
    "        return 3*6*a + 6*d + p\n",
    "    \n",
    "    binary_feature_vector = np.zeros((2*3*6,))\n",
    "    dealer, player_sum = state[\"dealer\"], state[\"player_sum\"]\n",
    "    dealer_intervals = [[1,4], [4,7],[7,10]]\n",
    "    dealer_cuboids = [np.linspace(dealer_interval[0], dealer_interval[1], dealer_interval[1]-dealer_interval[0]+1) for dealer_interval in dealer_intervals]\n",
    "    player_intervals = [[1,6], [4,9], [7,12], [10,15], [13,18], [16,21]]\n",
    "    player_cuboids = [np.linspace(player_interval[0], player_interval[1], player_interval[1]-player_interval[0]+1) for player_interval in player_intervals]    \n",
    "    \n",
    "    dealer_to_activate, player_to_activate = [], []\n",
    "    action_to_activate = [action]\n",
    "    \n",
    "    for k,dealer_cuboid in enumerate(dealer_cuboids):\n",
    "        if dealer in dealer_cuboid:\n",
    "            dealer_to_activate.append(k)\n",
    "    for j,player_cuboid in enumerate(player_cuboids):\n",
    "        if player_sum in player_cuboid:\n",
    "            player_to_activate.append(j)\n",
    "    \n",
    "    couples = list(itertools.product(action_to_activate, dealer_to_activate, player_to_activate))\n",
    "    index_couples = [turn_couple_to_index(couple) for couple in couples]\n",
    "    for index in index_couples:\n",
    "        binary_feature_vector[index]=1\n",
    "    return binary_feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "state  = {\"dealer\":10,\"player_sum\":10}\n",
    "action = 0\n",
    "print(binary_feature(state, action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def policy_epsilon_greedy2(N0, state, theta, epsilon):\n",
    "        \"\"\"Pick action epsilon-greedily\"\"\"\n",
    "        value_hit, value_stick = binary_feature(state, 0), binary_feature(state, 1)\n",
    "        epsilon = epsilon\n",
    "        p = np.random.binomial(1,epsilon_t)\n",
    "        max_index = np.argmax([value_hit, value_stick])\n",
    "        min_index = np.argmin([value_hit, value_stick])\n",
    "        if max_index!=min_index:\n",
    "            if p == 0:\n",
    "                index_action = max_index\n",
    "\n",
    "            else:\n",
    "                index_action = min_index\n",
    "        else:\n",
    "             index_action = np.random.binomial(1,0.5)\n",
    "        return index_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Sarsa_Q_approx(iterations, N0, discount_factor, Lambda, value_star):\n",
    "    \"\"\"Implements SARSA(Lambda) using Q function approximation\"\"\"\n",
    "    MSEs = []\n",
    "    actions = [\"Hit\", \"Stick\"]\n",
    "    \n",
    "    theta =  np.zeros(3 ∗ 6 ∗ 2,)\n",
    "    eligibility_traces = None \n",
    "    epsilon = 0.05\n",
    "    alpha = 0.01\n",
    "    for it in range(iterations):\n",
    "        \n",
    "        \"\"\"plays one episode\"\"\"\n",
    "        eligibility_traces = np.zeros(3 ∗ 6 ∗ 2,)\n",
    "        game = Easy21()\n",
    "        visits = []\n",
    "        ##Action chosen epsilon-greedily\n",
    "        first_state = game.state\n",
    "        index_action = policy_epsilon_greed2(N0, first_state, theta, epsilon)\n",
    "        \"\"\"plays game epsilon-greedily\"\"\"\n",
    "        while game.isTerminal == False:\n",
    "            \n",
    "            last_state = game.state\n",
    "            dealer, player_sum = last_state[\"dealer\"], last_state[\"player_sum\"]\n",
    "            \n",
    "            pick_action = actions[index_action]\n",
    "            \n",
    "            _,reward = game.step(pick_action)\n",
    "            binary_feat = binary_feature(last_state, index_action)\n",
    "            eligibility_traces += binary_feat\n",
    "\n",
    "            if game.isTerminal == False:\n",
    "                next_state = game.state\n",
    "                next_dealer , next_player_sum = next_state[\"dealer\"], next_state[\"player_sum\"]\n",
    "                next_index_action = policy_epsilon_greedy(N0, next_state, theta, epsilon)\n",
    "                \n",
    "                target = reward + discount_factor * np.dot(binary_feature(next_state, next_index_action).transpose(), theta)\n",
    "                index_action = next_index_action\n",
    "\n",
    "            else: \n",
    "                target = reward\n",
    "            delta = target - np.dot(binary_feat.transpose(), theta)\n",
    "            delta_tot = eligibility_traces * delta  * alpha\n",
    "            ##We update the weight vector\n",
    "            theta += delta_tot\n",
    "             \n",
    "            eligibility_traces = discount_factor * Lambda * eligibility_traces\n",
    "        \"\"\"episode ended\"\"\"\n",
    "       \n",
    "        error_episode = np.linalg.norm(get_value(action_value)-value_star)**2 / (2 * 22 * 10)\n",
    "        MSEs.append(error_episode)\n",
    "    return MSEs, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_value_from_theta(theta):\n",
    "    value = np.zeros((10,21))\n",
    "    for i in range(1,11):\n",
    "        for j in range(1,22):\n",
    "            value[i-1,j-1] = np.maximum(\n",
    "                np.dot(binary_feature({\"dealer\":i, \"player_sum\":j}, 0 ).tranpose(), theta), \n",
    "                np.dot(binary_feature({\"dealer\":i, \"player_sum\":j}, 1 ).tranpose(), theta))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
